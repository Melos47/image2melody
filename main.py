"""
Image to 8-bit Melody Converter
1-bit Dithering Mac OS Classic Style UI
ä½¿ç”¨pygame.mixerç›´æ¥ç”Ÿæˆæ³¢å½¢å£°éŸ³ï¼ˆæ— éœ€MIDIè®¾å¤‡ï¼‰
Data Moshing Animation Effect
"""
import tkinter as tk
from tkinter import filedialog, messagebox
from tkinter import font as tkfont
from PIL import Image, ImageTk, ImageDraw, ImageFilter, ImageChops
import threading
import os
import pygame
import random
from image_processor import ImageProcessor
from melody_generator import MelodyGenerator


class Image2MelodyApp:
    def __init__(self, root):
        self.root = root
        self.root.title("Scrapbook - Image2Melody")
        self.root.geometry("1000x800")  # å¢å¤§çª—å£å°ºå¯¸
        
        # 1-bit Dithering Mac OS Classic Style Colors
        self.bg_black = "#010101"           # èƒŒæ™¯é»‘è‰²
        self.primary_pink = "#C87488"       # ä¸»é¢˜è‰² r:200 g:116 b:136
        self.hover_beige = "#CDBEB8"        # é€‰ä¸­/hover r:205 g:190 b:184
        self.white = "#FFFFFF"              # ç™½è‰²ç”¨äºå¯¹æ¯”
        
        # Dithering patterns (for 1-bit style)
        self.dither_pattern_dark = None
        self.dither_pattern_light = None
        
        self.root.configure(bg=self.bg_black)
        
        # Initialize processors
        self.image_processor = ImageProcessor()
        self.melody_generator = MelodyGenerator()
        
        # State variables
        self.current_image_path = None
        self.current_image = None
        self.pixelated_image = None
        self.pixel_size = 10  # åƒç´ æ–¹å—å¤§å° (10Ã—10)
        
        # Animation state
        self.is_animating = False
        self.animation_paused = False
        self.current_pixel_index = 0
        self.rgb_data_list = []
        self.grid_width = 0
        self.grid_height = 0
        self.octave_shift = 0
        
        # Animation speed control (1.0 = normal, 0.5 = 2x faster, 2.0 = 2x slower)
        self.speed_multiplier = 1.0
        
        # Data moshing state
        self.glitch_frames = []
        self.moshing_intensity = 0
        self.trace_background = None  # ç”¨äºæ¸æ·¡traceæ•ˆæœçš„èƒŒæ™¯å›¾åƒ
        self.glitch_history = None  # ç”¨äºç´¯ç§¯ glitch æ•ˆæœçš„å†å²å±‚
        
        # Recording state
        self.is_recording = False
        self.animation_frames = []  # ä¿å­˜åŠ¨ç”»å¸§
        self.recorded_audio_data = []  # ä¿å­˜éŸ³é¢‘æ•°æ®ï¼ˆæ³¢å½¢æ•°ç»„ï¼‰
        self.frame_timestamps = []  # ä¿å­˜å¸§æ—¶é—´æˆ³
        
        # åˆå§‹åŒ–éŸ³é¢‘ç³»ç»Ÿ
        self.init_audio()
        
        # åˆ›å»ºæŠ–åŠ¨å›¾æ¡ˆ
        self.create_dither_patterns()
        
        # åŠ è½½åƒç´ å­—ä½“
        self.load_pixel_font()
        
        self.setup_ui()
        self.setup_keyboard_bindings()
    
    def create_dither_patterns(self):
        """åˆ›å»º1-bitæŠ–åŠ¨å›¾æ¡ˆï¼ˆMac OS Classicé£æ ¼ï¼‰"""
        # åˆ›å»ºæŠ–åŠ¨å›¾æ¡ˆ - ç”¨äºæ¨¡æ‹Ÿç°åº¦
        pattern_size = 8
        
        # 50% æŠ–åŠ¨å›¾æ¡ˆï¼ˆæ£‹ç›˜æ ¼ï¼‰
        pattern_50 = Image.new('1', (pattern_size, pattern_size))
        pixels = pattern_50.load()
        for y in range(pattern_size):
            for x in range(pattern_size):
                pixels[x, y] = (x + y) % 2
        self.dither_pattern_dark = pattern_50
        
        # 25% æŠ–åŠ¨å›¾æ¡ˆï¼ˆç¨€ç–ç‚¹é˜µï¼‰
        pattern_25 = Image.new('1', (pattern_size, pattern_size))
        pixels = pattern_25.load()
        for y in range(pattern_size):
            for x in range(pattern_size):
                pixels[x, y] = (x % 2 == 0 and y % 2 == 0)
        self.dither_pattern_light = pattern_25
    
    def apply_1bit_pixelation(self, image):
        """Convert image to bitmap style with classic halftone effect
        
        Features:
        1. Ordered dithering for bitmap appearance
        2. Classic halftone dot patterns
        3. High contrast black and white with colored midtones
        """
        # Convert to RGB and grayscale
        img_rgb = image.convert('RGB')
        img_gray = image.convert('L')
        rgb_pixels = img_rgb.load()
        gray_pixels = img_gray.load()
        width, height = img_rgb.size
        
        # Create result image
        result = Image.new('RGB', (width, height))
        result_pixels = result.load()
        
        # Bitmap color palette (reduced palette for bitmap effect)
        palette = {
            'black': (1, 1, 1),               # Pure black
            'dark_pink': (100, 50, 70),       # Dark pink
            'mid_pink': (200, 116, 136),      # Main pink
            'light_pink': (230, 170, 190),    # Light pink
            'beige': (205, 190, 184),         # Beige
            'light_beige': (240, 220, 210),   # Light beige
            'white': (255, 255, 255)          # Pure white
        }
        
        # Ordered dithering matrix (8x8 Bayer matrix for bitmap effect)
        bayer_matrix = [
            [ 0, 32,  8, 40,  2, 34, 10, 42],
            [48, 16, 56, 24, 50, 18, 58, 26],
            [12, 44,  4, 36, 14, 46,  6, 38],
            [60, 28, 52, 20, 62, 30, 54, 22],
            [ 3, 35, 11, 43,  1, 33,  9, 41],
            [51, 19, 59, 27, 49, 17, 57, 25],
            [15, 47,  7, 39, 13, 45,  5, 37],
            [63, 31, 55, 23, 61, 29, 53, 21]
        ]
        
        # Process each pixel with bitmap effect
        for y in range(height):
            for x in range(width):
                brightness = gray_pixels[x, y]
                r, g, b = rgb_pixels[x, y]
                
                # Calculate color temperature
                color_temp = (r - b) / 255.0 if (r + b) > 0 else 0
                
                # Get dithering threshold from Bayer matrix
                threshold_index = bayer_matrix[y % 8][x % 8]
                threshold = (threshold_index / 64.0) * 255
                
                # Apply ordered dithering to create bitmap effect
                if brightness < threshold * 0.2:  # Very dark
                    color = palette['black']
                elif brightness < threshold * 0.4:  # Dark
                    if color_temp > 0:
                        color = palette['dark_pink']
                    else:
                        color = palette['black']
                elif brightness < threshold * 0.6:  # Mid-dark
                    if color_temp > 0.1:
                        color = palette['mid_pink']
                    else:
                        color = palette['dark_pink']
                elif brightness < threshold * 0.8:  # Mid
                    if color_temp > 0:
                        color = palette['light_pink']
                    else:
                        color = palette['beige']
                elif brightness < threshold * 1.0:  # Mid-light
                    if color_temp > -0.1:
                        color = palette['light_pink']
                    else:
                        color = palette['light_beige']
                else:  # Bright
                    if color_temp > -0.2:
                        color = palette['light_pink']
                    else:
                        color = palette['white']
                
                result_pixels[x, y] = color
        
        print(f"âœ“ Bitmap effect applied (ordered dithering + halftone)")
        return result
    
    def apply_floyd_steinberg_dither(self, image, threshold=128, max_size=800):
        """Apply Floyd-Steinberg dithering to convert image to 1-bit
        
        Args:
            image: PIL Image object
            threshold: Brightness threshold (default 128)
            max_size: Maximum dimension to resize large images (default 800)
        """
        # Resize large images to prevent hanging
        width, height = image.size
        if width > max_size or height > max_size:
            # Calculate new size maintaining aspect ratio
            ratio = min(max_size / width, max_size / height)
            new_width = int(width * ratio)
            new_height = int(height * ratio)
            image = image.resize((new_width, new_height), Image.Resampling.LANCZOS)
            print(f"âš  Large image resized: {width}Ã—{height} â†’ {new_width}Ã—{new_height}")
        
        # Convert to grayscale
        img = image.convert('L')
        pixels = img.load()
        width, height = img.size
        
        # Process with progress updates
        total_pixels = width * height
        processed = 0
        last_update = 0
        
        for y in range(height):
            for x in range(width):
                old_pixel = pixels[x, y]
                new_pixel = 255 if old_pixel > threshold else 0
                pixels[x, y] = int(new_pixel)
                
                # Calculate quantization error
                quant_error = old_pixel - new_pixel
                
                # Distribute error to neighboring pixels (Floyd-Steinberg)
                if x + 1 < width:
                    pixels[x + 1, y] = int(min(255, max(0, pixels[x + 1, y] + quant_error * 7 / 16)))
                
                if x - 1 >= 0 and y + 1 < height:
                    pixels[x - 1, y + 1] = int(min(255, max(0, pixels[x - 1, y + 1] + quant_error * 3 / 16)))
                
                if y + 1 < height:
                    pixels[x, y + 1] = int(min(255, max(0, pixels[x, y + 1] + quant_error * 5 / 16)))
                
                if x + 1 < width and y + 1 < height:
                    pixels[x + 1, y + 1] = int(min(255, max(0, pixels[x + 1, y + 1] + quant_error * 1 / 16)))
                
                # Update progress every 10%
                processed += 1
                progress = int((processed / total_pixels) * 100)
                if progress >= last_update + 10:
                    last_update = progress
                    print(f"  Dithering: {progress}% complete...")
        
        # Convert back to RGB with pink/beige colors for 1-bit effect
        dithered = Image.new('RGB', (width, height))
        dithered_pixels = dithered.load()
        
        for y in range(height):
            for x in range(width):
                if pixels[x, y] > 128:
                    # White pixels -> Beige
                    dithered_pixels[x, y] = (205, 190, 184)  # hover_beige
                else:
                    # Black pixels -> Black
                    dithered_pixels[x, y] = (1, 1, 1)  # bg_black
        
        print("âœ“ Dithering complete!")
        return dithered
    
    def apply_data_moshing(self, image, intensity=0.0):
        """Apply enhanced glitch effects inspired by retro web aesthetics
        
        åŒ…æ‹¬ï¼š
        1. RGB é€šé“åˆ†ç¦»ï¼ˆChromatic Aberrationï¼‰
        2. æ‰«æçº¿æ•…éšœï¼ˆScanline Glitchï¼‰
        3. åƒç´ ä½ç§»ï¼ˆPixel Displacementï¼‰
        4. é¢œè‰²å¤±çœŸï¼ˆColor Corruptionï¼‰
        5. éšæœºå™ªç‚¹ï¼ˆRandom Noiseï¼‰
        """
        if intensity <= 0:
            return image
        
        img = image.copy()
        width, height = img.size
        
        # 1. RGB é€šé“åˆ†ç¦»æ•ˆæœï¼ˆChromatic Aberrationï¼‰
        if intensity > 0.1 and random.random() < intensity:
            # åˆ†ç¦»RGBé€šé“
            if img.mode == 'RGB' or img.mode == 'RGBA':
                r, g, b = img.split()[:3]
                
                # éšæœºåç§»é‡
                offset_x = int(random.randint(-5, 5) * intensity)
                offset_y = int(random.randint(-2, 2) * intensity)
                
                # åˆ›å»ºåç§»åçš„é€šé“
                r_shifted = ImageChops.offset(r, offset_x, 0)
                b_shifted = ImageChops.offset(b, -offset_x, offset_y)
                
                # é‡æ–°åˆæˆ
                if img.mode == 'RGBA':
                    a = img.split()[3]
                    img = Image.merge('RGBA', (r_shifted, g, b_shifted, a))
                else:
                    img = Image.merge('RGB', (r_shifted, g, b_shifted))
        
        # 2. æ‰«æçº¿æ•…éšœæ•ˆæœ
        pixels = img.load()
        num_scanlines = int(height * intensity * 0.3)
        
        for _ in range(num_scanlines):
            line_y = random.randint(0, height - 1)
            line_width = random.randint(int(width * 0.2), int(width * 0.8))
            start_x = random.randint(0, max(0, width - line_width))
            
            # æ‰«æçº¿ç±»å‹
            scanline_type = random.choice(['repeat', 'shift', 'corrupt', 'bright'])
            
            for lx in range(line_width):
                px = start_x + lx
                if px < width and px > 0:
                    try:
                        if scanline_type == 'repeat':
                            # é‡å¤å‰ä¸€ä¸ªåƒç´ 
                            pixels[px, line_y] = pixels[px - 1, line_y]
                        elif scanline_type == 'shift':
                            # å‚ç›´åç§»
                            shift_y = min(height - 1, max(0, line_y + random.randint(-2, 2)))
                            pixels[px, line_y] = pixels[px, shift_y]
                        elif scanline_type == 'corrupt':
                            # Color corruption - bitmap style palette
                            corrupt_colors = [
                                (1, 1, 1),           # Black
                                (100, 50, 70),       # Dark pink
                                (200, 116, 136),     # Main pink
                                (230, 170, 190),     # Light pink
                                (255, 255, 255)      # White
                            ]
                            color = random.choice(corrupt_colors)
                            if img.mode == 'RGB':
                                pixels[px, line_y] = color
                            else:
                                pixels[px, line_y] = color + (255,)
                        elif scanline_type == 'bright':
                            # å¢åŠ äº®åº¦
                            pixel = pixels[px, line_y]
                            if isinstance(pixel, tuple) and len(pixel) >= 3:
                                r, g, b = pixel[:3]
                                pixels[px, line_y] = (
                                    min(255, int(r * 1.5)),
                                    min(255, int(g * 1.5)),
                                    min(255, int(b * 1.5))
                                ) if img.mode == 'RGB' else (
                                    min(255, int(r * 1.5)),
                                    min(255, int(g * 1.5)),
                                    min(255, int(b * 1.5)),
                                    pixel[3] if len(pixel) == 4 else 255
                                )
                    except:
                        pass
        
        # 3. åƒç´ å—ä½ç§»
        num_displacements = int(width * height * intensity * 0.02)
        
        for _ in range(num_displacements):
            block_size = random.randint(5, 20)
            x = random.randint(0, width - block_size - 1)
            y = random.randint(0, height - block_size - 1)
            dx = random.randint(-30, 30)
            dy = random.randint(-10, 10)
            
            # å¤åˆ¶å—åˆ°æ–°ä½ç½®
            for by in range(block_size):
                for bx in range(block_size):
                    src_x, src_y = x + bx, y + by
                    dst_x = max(0, min(width - 1, src_x + dx))
                    dst_y = max(0, min(height - 1, src_y + dy))
                    try:
                        pixels[dst_x, dst_y] = pixels[src_x, src_y]
                    except:
                        pass
        
        # 4. éšæœºå™ªç‚¹ï¼ˆé¢œè‰²æ•…éšœï¼‰
        num_noise = int(width * height * intensity * 0.01)
        
        for _ in range(num_noise):
            nx = random.randint(0, width - 1)
            ny = random.randint(0, height - 1)
            
            # Bitmap style noise palette
            noise_colors = [
                (1, 1, 1),           # Black
                (100, 50, 70),       # Dark pink
                (200, 116, 136),     # Main pink
                (230, 170, 190),     # Light pink
                (205, 190, 184),     # Beige
                (240, 220, 210),     # Light beige
                (255, 255, 255)      # White
            ]
            
            try:
                color = random.choice(noise_colors)
                if img.mode == 'RGBA':
                    pixels[nx, ny] = color + (255,)
                else:
                    pixels[nx, ny] = color
            except:
                pass
        
        return img
    
    def apply_subtle_shift(self, img):
        """åº”ç”¨å¾®å¼±çš„æ•´ä½“ç”»é¢shiftæ•ˆæœï¼ˆwiredfriendé£æ ¼ï¼‰
        
        åˆ›å»ºå¾®å¦™çš„1-bitç²’å­ä½ç§»ï¼Œå¢åŠ åŠ¨æ€æ„Ÿ
        """
        import random
        from PIL import ImageChops
        
        width, height = img.size
        
        # 1. å¾®å¼±çš„æ•´ä½“åç§»ï¼ˆ0-2åƒç´ ï¼‰
        global_shift_x = random.randint(-2, 2)
        global_shift_y = random.randint(-1, 1)
        
        # åªåœ¨éé›¶åç§»æ—¶åº”ç”¨
        if global_shift_x != 0 or global_shift_y != 0:
            img = ImageChops.offset(img, global_shift_x, global_shift_y)
        
        # 2. æå°‘æ•°éšæœºåƒç´ çš„å¾®ä½ç§»ï¼ˆ1-bitç²’å­æ•ˆæœï¼‰
        if random.random() < 0.3:  # 30%æ¦‚ç‡
            pixels = img.load()
            num_particles = int(width * height * 0.002)  # 0.2%çš„åƒç´ 
            
            for _ in range(num_particles):
                x = random.randint(0, width - 1)
                y = random.randint(0, height - 1)
                
                # éšæœºå°èŒƒå›´ä½ç§»
                dx = random.randint(-1, 1)
                dy = random.randint(-1, 1)
                
                # ç›®æ ‡ä½ç½®
                nx = max(0, min(width - 1, x + dx))
                ny = max(0, min(height - 1, y + dy))
                
                try:
                    # äº¤æ¢åƒç´ 
                    temp = pixels[x, y]
                    pixels[x, y] = pixels[nx, ny]
                    pixels[nx, ny] = temp
                except:
                    pass
        
        return img
    
    def load_pixel_font(self):
        """åŠ è½½åƒç´ é£æ ¼å­—ä½“ Jersey10-Regular.ttf"""
        # åœ¨macOSä¸Šï¼Œtkinterå¯¹è‡ªå®šä¹‰TTFå­—ä½“æ”¯æŒæœ‰é™
        # å°è¯•å¤šç§æ–¹æ³•åŠ è½½å­—ä½“
        
        # æ–¹æ³•1: å°è¯•ä½¿ç”¨å·²å®‰è£…çš„ Jersey10 å­—ä½“
        jersey_font_names = [
            "Jersey 10",           # ç³»ç»Ÿè¯†åˆ«åç§°ï¼ˆå·²ç¡®è®¤ï¼Œå¸¦ç©ºæ ¼ï¼ï¼‰
            "Jersey10",            # æ— ç©ºæ ¼ç‰ˆæœ¬
            "Jersey 10 Regular",   # å®Œæ•´åç§°
            "Jersey10-Regular",    # è¿å­—ç¬¦ç‰ˆæœ¬
        ]
        
        for font_name in jersey_font_names:
            try:
                test_font = tkfont.Font(family=font_name, size=16)
                self.pixel_font_large = (font_name, 36, "normal")  # ä» 28 å¢åŠ åˆ° 36
                self.pixel_font_medium = (font_name, 24, "normal") # ä» 20 å¢åŠ åˆ° 24
                self.pixel_font_small = (font_name, 16, "normal")  # ä» 14 å¢åŠ åˆ° 16
                print(f"âœ“ Using {font_name} font")
                return
            except:
                continue
        
        # æ–¹æ³•2: å°è¯• Silkscreenï¼ˆå¤‡ç”¨ï¼‰
        print("âš  Jersey 10 not found, trying Silkscreen...")
        silkscreen_font_names = [
            "Silkscreen",
            "Silkscreen Regular",
        ]
        
        for font_name in silkscreen_font_names:
            try:
                test_font = tkfont.Font(family=font_name, size=16)
                self.pixel_font_large = (font_name, 32, "normal")  # ä» 28 å¢åŠ åˆ° 32
                self.pixel_font_medium = (font_name, 24, "normal") # ä» 20 å¢åŠ åˆ° 24
                self.pixel_font_small = (font_name, 16, "normal")  # ä» 14 å¢åŠ åˆ° 16
                print(f"âœ“ Using {font_name} font (alternative)")
                return
            except:
                continue
        
        # æ–¹æ³•3: å°è¯• Jersey10 Chartedï¼ˆå¤‡ç”¨ï¼‰
        print("âš  Trying Jersey10 Charted...")
        jersey_charted_names = [
            "Jersey 10 Charted",
            "Jersey10 Charted",
        ]
        
        for font_name in jersey_charted_names:
            try:
                test_font = tkfont.Font(family=font_name, size=16)
                self.pixel_font_large = (font_name, 32, "normal")
                self.pixel_font_medium = (font_name, 24, "normal")
                self.pixel_font_small = (font_name, 16, "normal")
                print(f"âœ“ Using {font_name} font (alternative)")
                return
            except:
                continue
        
        # æ–¹æ³•4: ä½¿ç”¨macOSä¸Šå¯ç”¨çš„åƒç´ é£æ ¼ç­‰å®½å­—ä½“
        print("âš  Pixel fonts not found, trying system fonts...")
        pixel_fonts = [
            "Monaco",      # macOSå†…ç½®ï¼Œåƒç´ é£æ ¼
            "Menlo",       # macOSå†…ç½®ï¼Œæ¸…æ™°ç­‰å®½
            "Courier New", # è·¨å¹³å°
            "Courier"      # å¤‡ç”¨
        ]
        
        for font_name in pixel_fonts:
            try:
                test_font = tkfont.Font(family=font_name, size=16)
                self.pixel_font_large = (font_name, 32, "bold")
                self.pixel_font_medium = (font_name, 24, "bold")
                self.pixel_font_small = (font_name, 16, "normal")
                print(f"âœ“ Using {font_name} font (system font)")
                return
            except:
                continue
        
        # æœ€åå¤‡ç”¨
        print(f"âš  Using default Courier font")
        self.pixel_font_large = ("Courier", 24, "bold")
        self.pixel_font_medium = ("Courier", 18, "bold")
        self.pixel_font_small = ("Courier", 12, "bold")
    
    def setup_ui(self):
        """Setup Mac OS Classic 1-bit dithering style UI"""
        # é¡¶éƒ¨æ ‡é¢˜æ  - Mac OS Classicé£æ ¼ï¼ˆæ¡çº¹å›¾æ¡ˆï¼‰
        title_frame = tk.Frame(self.root, bg=self.primary_pink, height=32)
        title_frame.pack(fill=tk.X)
        title_frame.pack_propagate(False)
        
        # åˆ›å»ºæ¡çº¹èƒŒæ™¯canvasï¼ˆæ¨¡æ‹ŸMac OSæ ‡é¢˜æ ï¼‰
        title_canvas = tk.Canvas(
            title_frame,
            bg=self.primary_pink,
            height=32,
            highlightthickness=0
        )
        title_canvas.pack(fill=tk.BOTH, expand=True)
        
        # ç»˜åˆ¶å‚ç›´æ¡çº¹
        for i in range(0, 1400, 2):  # å¢åŠ èŒƒå›´ä»¥é€‚åº”æ›´å¤§çª—å£
            title_canvas.create_line(i, 0, i, 32, fill=self.bg_black, width=1)
        
        # æ ‡é¢˜æ–‡å­—ï¼ˆå±…ä¸­ï¼‰
        self.title_text_id = title_canvas.create_text(
            500, 16,  # å›ºå®šä½ç½®
            text="NetDream###8",
            font=self.pixel_font_medium,
            fill=self.bg_black,
            anchor=tk.CENTER
        )
        
        # æ§åˆ¶æ  - ä½¿ç”¨beigeé¢œè‰²
        control_frame = tk.Frame(self.root, bg=self.hover_beige, height=48)
        control_frame.pack(fill=tk.X, pady=(2, 0))
        control_frame.pack_propagate(False)
        
        # åˆ›å»ºæ§åˆ¶æ canvasï¼ˆå¸¦è¾¹æ¡†ï¼‰
        control_canvas = tk.Canvas(
            control_frame,
            bg=self.hover_beige,
            height=48,
            highlightthickness=2,
            highlightbackground=self.primary_pink
        )
        control_canvas.pack(fill=tk.BOTH, expand=True, padx=4, pady=4)
        
        # æ§åˆ¶æ–‡å­—
        control_canvas.create_text(
            20, 24,  # å‚ç›´å±…ä¸­
            text="CONTROLS: [W]â†‘ [S]â†“ [A]â† [D]â†’ [SPACE]â¸ [â†‘â†“â†â†’]Speed [R]Reset",
            font=self.pixel_font_small,
            fill=self.bg_black,
            anchor=tk.W
        )
        
        # Speedæ˜¾ç¤ºï¼ˆä¸­é—´ä½ç½®ï¼‰
        self.speed_display_id = control_canvas.create_text(
            700, 24,
            text="SPEED: 1.0x",
            font=self.pixel_font_small,
            fill=self.bg_black,
            anchor=tk.CENTER
        )
        
        # Pitchæ˜¾ç¤ºï¼ˆå³ä¾§å¯¹é½ï¼‰
        self.octave_display_id = control_canvas.create_text(
            980, 24,  # å›ºå®šä½ç½®ï¼Œå‚ç›´å±…ä¸­
            text="PITCH: +0",
            font=self.pixel_font_small,
            fill=self.bg_black,
            anchor=tk.E
        )
        self.octave_canvas = control_canvas  # ä¿å­˜å¼•ç”¨ç”¨äºæ›´æ–°
        
        # ä¸»æ˜¾ç¤ºåŒºåŸŸ - å¸¦Macé£æ ¼è¾¹æ¡†
        main_frame = tk.Frame(self.root, bg=self.bg_black)
        main_frame.pack(fill=tk.BOTH, expand=True, padx=8, pady=8)
        
        # åˆ›å»ºMacé£æ ¼çª—å£è¾¹æ¡†
        canvas_outer = tk.Frame(main_frame, bg=self.primary_pink, bd=3, relief=tk.RIDGE)
        canvas_outer.pack(fill=tk.BOTH, expand=True)
        
        canvas_inner = tk.Frame(canvas_outer, bg=self.bg_black, bd=2)
        canvas_inner.pack(fill=tk.BOTH, expand=True, padx=2, pady=2)
        
        self.image_canvas = tk.Canvas(
            canvas_inner,
            bg=self.bg_black,
            highlightthickness=0
        )
        self.image_canvas.pack(fill=tk.BOTH, expand=True)
        
        # ç»˜åˆ¶åŠ è½½æŒ‰é’®
        self.root.after(100, self.draw_load_button)
        
        # åº•éƒ¨çŠ¶æ€æ  - Macé£æ ¼
        status_frame = tk.Frame(self.root, bg=self.hover_beige, height=32)
        status_frame.pack(fill=tk.X, side=tk.BOTTOM)
        status_frame.pack_propagate(False)
        
        status_canvas = tk.Canvas(
            status_frame,
            bg=self.hover_beige,
            height=32,
            highlightthickness=1,
            highlightbackground=self.primary_pink
        )
        status_canvas.pack(fill=tk.BOTH, expand=True)
        
        # çŠ¶æ€æ–‡å­—
        self.status_text_id = status_canvas.create_text(
            20, 16,
            text="[ READY ] Load image to start",
            font=self.pixel_font_small,
            fill=self.bg_black,
            anchor=tk.W
        )
        self.status_canvas = status_canvas  # ä¿å­˜å¼•ç”¨ç”¨äºæ›´æ–°
        
        self.image_canvas.bind('<Button-1>', self.on_canvas_click)
    
    def draw_load_button(self):
        """Draw Mac OS Classic style load button in center of canvas"""
        self.image_canvas.delete("all")
        
        self.image_canvas.update()
        canvas_width = self.image_canvas.winfo_width()
        canvas_height = self.image_canvas.winfo_height()
        
        if canvas_width <= 1:
            canvas_width = 800
        if canvas_height <= 1:
            canvas_height = 500
        
        center_x = canvas_width // 2
        center_y = canvas_height // 2
        
        # Macé£æ ¼æŒ‰é’®å°ºå¯¸
        button_width = 200
        button_height = 70
        button_spacing = 30
        
        # LOAD IMAGE æŒ‰é’®ï¼ˆå·¦ä¾§ï¼‰
        load_x = center_x - button_width // 2 - button_spacing
        self.load_button_rect = self.image_canvas.create_rectangle(
            load_x - button_width // 2,
            center_y - button_height // 2,
            load_x + button_width // 2,
            center_y + button_height // 2,
            fill=self.hover_beige,
            outline=self.primary_pink,
            width=3,
            tags="load_button"
        )
        
        self.image_canvas.create_text(
            load_x,
            center_y - 8,
            text="LOAD IMAGE",
            font=self.pixel_font_medium,
            fill=self.bg_black,
            tags="load_button"
        )
        
        self.image_canvas.create_text(
            load_x,
            center_y + 18,
            text="From file",
            font=self.pixel_font_small,
            fill=self.bg_black,
            tags="load_button"
        )
        
        # CAMERA æŒ‰é’®ï¼ˆå³ä¾§ï¼‰
        camera_x = center_x + button_width // 2 + button_spacing
        self.camera_button_rect = self.image_canvas.create_rectangle(
            camera_x - button_width // 2,
            center_y - button_height // 2,
            camera_x + button_width // 2,
            center_y + button_height // 2,
            fill=self.hover_beige,
            outline=self.primary_pink,
            width=3,
            tags="camera_button"
        )
        
        self.image_canvas.create_text(
            camera_x,
            center_y - 8,
            text="CAMERA",
            font=self.pixel_font_medium,
            fill=self.bg_black,
            tags="camera_button"
        )
        
        self.image_canvas.create_text(
            camera_x,
            center_y + 18,
            text="Live capture",
            font=self.pixel_font_small,
            fill=self.bg_black,
            tags="camera_button"
        )
        
        # Hoveræ•ˆæœ - LOADæŒ‰é’®
        self.image_canvas.tag_bind("load_button", "<Enter>", 
            lambda e: [self.image_canvas.itemconfig(self.load_button_rect, fill=self.primary_pink),
                      self.image_canvas.config(cursor="hand2")])
        self.image_canvas.tag_bind("load_button", "<Leave>", 
            lambda e: [self.image_canvas.itemconfig(self.load_button_rect, fill=self.hover_beige),
                      self.image_canvas.config(cursor="")])
        
        # Hoveræ•ˆæœ - CAMERAæŒ‰é’®
        self.image_canvas.tag_bind("camera_button", "<Enter>", 
            lambda e: [self.image_canvas.itemconfig(self.camera_button_rect, fill=self.primary_pink),
                      self.image_canvas.config(cursor="hand2")])
        self.image_canvas.tag_bind("camera_button", "<Leave>", 
            lambda e: [self.image_canvas.itemconfig(self.camera_button_rect, fill=self.hover_beige),
                      self.image_canvas.config(cursor="")])
    
    def on_canvas_click(self, event):
        """Canvas click event"""
        items = self.image_canvas.find_overlapping(event.x, event.y, event.x, event.y)
        if items and "load_button" in self.image_canvas.gettags(items[0]):
            self.load_image()
        elif items and "camera_button" in self.image_canvas.gettags(items[0]):
            self.capture_from_camera()
        elif items and "reload_button" in self.image_canvas.gettags(items[0]):
            self.reset_and_load()
    
    def setup_keyboard_bindings(self):
        """Setup keyboard bindings"""
        # Pitch control
        self.root.bind('<w>', lambda e: self.adjust_octave(12))
        self.root.bind('<W>', lambda e: self.adjust_octave(12))
        self.root.bind('<s>', lambda e: self.adjust_octave(-12))
        self.root.bind('<S>', lambda e: self.adjust_octave(-12))
        self.root.bind('<a>', lambda e: self.adjust_octave(-1))
        self.root.bind('<A>', lambda e: self.adjust_octave(-1))
        self.root.bind('<d>', lambda e: self.adjust_octave(1))
        self.root.bind('<D>', lambda e: self.adjust_octave(1))
        
        # Speed control
        self.root.bind('<Up>', lambda e: self.adjust_speed(0.2))      # åŠ å¿«
        self.root.bind('<Down>', lambda e: self.adjust_speed(-0.2))   # å‡æ…¢
        self.root.bind('<Left>', lambda e: self.adjust_speed(-0.1))   # ç¨æ…¢
        self.root.bind('<Right>', lambda e: self.adjust_speed(0.1))   # ç¨å¿«
        self.root.bind('<r>', lambda e: self.reset_speed())           # é‡ç½®é€Ÿåº¦
        self.root.bind('<R>', lambda e: self.reset_speed())
        
        # Pause
        self.root.bind('<space>', lambda e: self.toggle_pause())
    
    def init_audio(self):
        """åˆå§‹åŒ–éŸ³é¢‘ç³»ç»Ÿï¼ˆä½¿ç”¨pygame.mixerï¼Œæ— éœ€MIDIè®¾å¤‡ï¼‰"""
        if self.melody_generator.audio_initialized:
            print("âœ“ Audio system ready")
            return True
        else:
            print("âœ— Audio initialization failed")
            messagebox.showwarning("Audio Warning", 
                "Could not initialize audio system.\nYou may not hear sounds during playback.")
            return False
    
    def adjust_octave(self, shift):
        """Adjust pitch"""
        if self.is_animating:
            self.octave_shift += shift
            self.octave_shift = max(-24, min(24, self.octave_shift))
            self.octave_canvas.itemconfig(self.octave_display_id, 
                                         text=f"PITCH: {self.octave_shift:+d}")
    
    def adjust_speed(self, delta):
        """è°ƒæ•´åŠ¨ç”»é€Ÿåº¦"""
        if self.is_animating:
            self.speed_multiplier += delta
            # é™åˆ¶é€Ÿåº¦èŒƒå›´ï¼š0.2x (5å€å¿«) åˆ° 3.0x (3å€æ…¢)
            self.speed_multiplier = max(0.2, min(3.0, self.speed_multiplier))
            speed_display = f"{1.0/self.speed_multiplier:.1f}x" if self.speed_multiplier > 0 else "MAX"
            self.octave_canvas.itemconfig(self.speed_display_id, 
                                         text=f"SPEED: {speed_display}")
            print(f"âš¡ Speed: {speed_display}")
    
    def reset_speed(self):
        """é‡ç½®é€Ÿåº¦åˆ°æ­£å¸¸"""
        if self.is_animating:
            self.speed_multiplier = 1.0
            self.octave_canvas.itemconfig(self.speed_display_id, 
                                         text="SPEED: 1.0x")
            print("âš¡ Speed reset to 1.0x")
    
    def toggle_pause(self):
        """Pause/resume animation"""
        if self.is_animating:
            self.animation_paused = not self.animation_paused
            if self.animation_paused:
                self.status_canvas.itemconfig(self.status_text_id, 
                                             text="[ PAUSED ] Press SPACE to resume")
            else:
                self.status_canvas.itemconfig(self.status_text_id, 
                                             text="[ PLAYING ] Generating melody...")
                self.animate_next_pixel()
    
    def load_image(self):
        """Load image"""
        file_path = filedialog.askopenfilename(
            title="Select an Image",
            filetypes=[
                ("Image Files", "*.png *.jpg *.jpeg *.bmp *.gif"),
                ("All Files", "*.*")
            ]
        )
        
        if file_path:
            try:
                self.current_image_path = file_path
                self.current_image = Image.open(file_path)
                
                self.display_image(self.current_image)
                self.show_start_animation_popup()
                
            except Exception as e:
                messagebox.showerror("Error", f"Failed to load image: {str(e)}")
    
    def capture_from_camera(self):
        """Capture image from camera and show in main canvas"""
        try:
            import cv2
        except ImportError:
            messagebox.showerror("Error", "opencv-python library is required for camera capture.\n\nInstall with:\npip install opencv-python")
            return
        
        # æ‰“å¼€æ‘„åƒå¤´
        self.camera_cap = cv2.VideoCapture(0)
        
        if not self.camera_cap.isOpened():
            messagebox.showerror("Error", "Could not open camera!")
            return
        
        self.camera_active = True
        self.camera_frame = None
        self.camera_paused = False
        self.camera_octave_shift = 0  # æ‘„åƒå¤´æ¨¡å¼çš„éŸ³é«˜åç§»
        self.camera_speed = 1.0  # æ‘„åƒå¤´éŸ³é¢‘æ’­æ”¾é€Ÿåº¦å€ç‡
        
        # åˆå§‹åŒ–å½•åˆ¶çŠ¶æ€
        self.camera_recording = True
        self.camera_frames = []
        self.camera_audio_notes = []
        
        # åœ¨ä¸» canvas ä¸Šæ˜¾ç¤ºæ‘„åƒå¤´é¢„è§ˆ
        self.update_camera_preview()
        
        # æ˜¾ç¤ºæ‘„åƒå¤´æ§åˆ¶æŒ‰é’®
        self.show_camera_controls()
        
        # ç»‘å®šé”®ç›˜æ§åˆ¶
        self.bind_camera_keyboard_controls()
    
    def update_camera_preview(self):
        """æ›´æ–°ä¸» canvas ä¸Šçš„æ‘„åƒå¤´é¢„è§ˆï¼Œå¹¶æ ¹æ®é¢œè‰²ç”Ÿæˆå®æ—¶å£°éŸ³"""
        if not self.camera_active:
            return
        
        import cv2
        import time
        
        ret, frame = self.camera_cap.read()
        if ret:
            # ä¿å­˜å½“å‰å¸§
            self.camera_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            
            # è½¬æ¢ä¸ºPIL Image
            img = Image.fromarray(self.camera_frame)
            
            # æ˜¾ç¤ºåœ¨ä¸» canvas ä¸Š
            self.display_image(img)
            
            # å¦‚æœæ­£åœ¨å½•åˆ¶ï¼Œä¿å­˜å¸§
            if self.camera_recording and not self.camera_paused:
                self.camera_frames.append(img.copy())
            
            # ğŸµ æ ¹æ®æ‘„åƒå¤´ç”»é¢ä¸­å¿ƒåŒºåŸŸç”Ÿæˆå®æ—¶å£°éŸ³ï¼ˆå¦‚æœæœªæš‚åœï¼‰
            if not self.camera_paused:
                self.play_camera_audio(img)
            
            # æ›´æ–°çŠ¶æ€æ˜¾ç¤º
            status = "PAUSED" if self.camera_paused else "RECORDING" if self.camera_recording else "LIVE"
            self.status_canvas.itemconfig(self.status_text_id,
                text=f"[ {status} ] Camera | Pitch: {self.camera_octave_shift:+d} | Speed: {self.camera_speed:.1f}x | Frames: {len(self.camera_frames)}"
            )
        
        # ç»§ç»­æ›´æ–°ï¼ˆæ ¹æ®é€Ÿåº¦è°ƒæ•´ï¼‰
        if self.camera_active:
            frame_delay = int(33 / self.camera_speed)  # åŸºç¡€ 30 FPSï¼Œå—é€Ÿåº¦å½±å“
            self.root.after(frame_delay, self.update_camera_preview)
    
    def show_camera_controls(self):
        """åœ¨ä¸» canvas ä¸Šæ˜¾ç¤ºæ‘„åƒå¤´æ§åˆ¶æŒ‰é’®ï¼ˆ4ä¸ªæŒ‰é’®ï¼‰"""
        self.image_canvas.delete("camera_control")
        
        canvas_width = self.image_canvas.winfo_width()
        canvas_height = self.image_canvas.winfo_height()
        
        if canvas_width <= 1:
            canvas_width = 800
        if canvas_height <= 1:
            canvas_height = 500
        
        # æŒ‰é’®ä½ç½®ï¼ˆåº•éƒ¨ä¸­å¤®ï¼Œ4ä¸ªæŒ‰é’®æ¨ªæ’ï¼‰
        center_x = canvas_width // 2
        bottom_y = canvas_height - 60
        
        button_width = 130
        button_height = 50
        button_spacing = 15
        
        # è®¡ç®—4ä¸ªæŒ‰é’®çš„èµ·å§‹ä½ç½®
        total_width = button_width * 4 + button_spacing * 3
        start_x = center_x - total_width // 2
        
        # æŒ‰é’®é…ç½® [æ–‡æœ¬, æ ‡ç­¾, å›è°ƒå‡½æ•°]
        buttons = [
            ("PAUSE", "pause_btn", self.toggle_camera_pause),
            ("SAVE", "save_btn", self.save_camera_recording),
            ("RELOAD", "reload_btn", self.reload_camera),
            ("EXIT", "exit_btn", self.cancel_camera)
        ]
        
        self.camera_button_rects = {}
        
        for i, (text, tag, callback) in enumerate(buttons):
            x = start_x + button_width // 2 + i * (button_width + button_spacing)
            
            # åˆ›å»ºæŒ‰é’®çŸ©å½¢
            rect_id = self.image_canvas.create_rectangle(
                x - button_width // 2,
                bottom_y - button_height // 2,
                x + button_width // 2,
                bottom_y + button_height // 2,
                fill=self.hover_beige,
                outline=self.primary_pink,
                width=3,
                tags=f"camera_control {tag}"
            )
            
            self.camera_button_rects[tag] = rect_id
            
            # åˆ›å»ºæŒ‰é’®æ–‡å­—
            self.image_canvas.create_text(
                x,
                bottom_y,
                text=text,
                font=self.pixel_font_medium,
                fill=self.bg_black,
                tags=f"camera_control {tag}"
            )
            
            # ç»‘å®šç‚¹å‡»äº‹ä»¶
            self.image_canvas.tag_bind(tag, "<Button-1>", lambda e, cb=callback: cb())
            
            # Hover æ•ˆæœ
            self.image_canvas.tag_bind(tag, "<Enter>", 
                lambda e, rect=rect_id: [self.image_canvas.itemconfig(rect, fill=self.primary_pink),
                                        self.image_canvas.config(cursor="hand2")])
            self.image_canvas.tag_bind(tag, "<Leave>", 
                lambda e, rect=rect_id: [self.image_canvas.itemconfig(rect, fill=self.hover_beige),
                                        self.image_canvas.config(cursor="")])
    
    def bind_camera_keyboard_controls(self):
        """ç»‘å®šæ‘„åƒå¤´æ¨¡å¼çš„é”®ç›˜æ§åˆ¶"""
        # W/S - éŸ³é«˜æ§åˆ¶ï¼ˆä¸Šå‡/ä¸‹é™å…«åº¦ï¼‰
        self.root.bind('w', lambda e: self.adjust_camera_octave(+1))
        self.root.bind('W', lambda e: self.adjust_camera_octave(+1))
        self.root.bind('s', lambda e: self.adjust_camera_octave(-1))
        self.root.bind('S', lambda e: self.adjust_camera_octave(-1))
        
        # A/D - å…«åº¦æ§åˆ¶ï¼ˆå¦ä¸€ç§æ–¹å¼ï¼‰
        self.root.bind('a', lambda e: self.adjust_camera_octave(-1))
        self.root.bind('A', lambda e: self.adjust_camera_octave(-1))
        self.root.bind('d', lambda e: self.adjust_camera_octave(+1))
        self.root.bind('D', lambda e: self.adjust_camera_octave(+1))
        
        # æ–¹å‘é”® - é€Ÿåº¦æ§åˆ¶
        self.root.bind('<Up>', lambda e: self.adjust_camera_speed(+0.2))
        self.root.bind('<Down>', lambda e: self.adjust_camera_speed(-0.2))
        self.root.bind('<Left>', lambda e: self.adjust_camera_speed(-0.2))
        self.root.bind('<Right>', lambda e: self.adjust_camera_speed(+0.2))
        
        # ç©ºæ ¼ - æš‚åœ/ç»§ç»­
        self.root.bind('<space>', lambda e: self.toggle_camera_pause())
    
    def adjust_camera_octave(self, delta):
        """è°ƒæ•´æ‘„åƒå¤´éŸ³é«˜ï¼ˆå…«åº¦ï¼‰"""
        if hasattr(self, 'camera_active') and self.camera_active:
            self.camera_octave_shift += delta * 12  # æ¯æ¬¡ç§»åŠ¨ä¸€ä¸ªå…«åº¦ï¼ˆ12ä¸ªåŠéŸ³ï¼‰
            self.camera_octave_shift = max(-24, min(24, self.camera_octave_shift))  # é™åˆ¶åœ¨Â±2ä¸ªå…«åº¦
            print(f"ğŸµ Camera octave: {self.camera_octave_shift:+d} semitones")
    
    def adjust_camera_speed(self, delta):
        """è°ƒæ•´æ‘„åƒå¤´æ’­æ”¾é€Ÿåº¦"""
        if hasattr(self, 'camera_active') and self.camera_active:
            self.camera_speed += delta
            self.camera_speed = max(0.2, min(3.0, self.camera_speed))  # é™åˆ¶åœ¨ 0.2x - 3.0x
            print(f"âš¡ Camera speed: {self.camera_speed:.1f}x")
    
    def toggle_camera_pause(self):
        """æš‚åœ/ç»§ç»­æ‘„åƒå¤´"""
        if hasattr(self, 'camera_active') and self.camera_active:
            self.camera_paused = not self.camera_paused
            status = "PAUSED" if self.camera_paused else "RESUMED"
            print(f"â¸ï¸  Camera {status}")
            
            # åœæ­¢å£°éŸ³
            if self.camera_paused:
                try:
                    pygame.mixer.stop()
                except:
                    pass
    
    def save_camera_recording(self):
        """ä¿å­˜æ‘„åƒå¤´å½•åˆ¶çš„è§†é¢‘å’ŒéŸ³é¢‘"""
        if not hasattr(self, 'camera_frames') or len(self.camera_frames) == 0:
            messagebox.showinfo("Info", "No frames recorded yet!")
            return
        
        print(f"ğŸ’¾ Saving camera recording: {len(self.camera_frames)} frames, {len(self.camera_audio_notes)} notes")
        
        # ä½¿ç”¨æ–‡ä»¶å¯¹è¯æ¡†
        from tkinter import filedialog
        
        # ä¿å­˜è§†é¢‘
        video_path = filedialog.asksaveasfilename(
            defaultextension=".mp4",
            filetypes=[("MP4 Video", "*.mp4"), ("All Files", "*.*")],
            title="Save Camera Video"
        )
        
        if video_path:
            try:
                import imageio
                import numpy as np
                
                # è®¡ç®— FPSï¼ˆå‡è®¾ 30 FPSï¼‰
                fps = 30
                
                # è½¬æ¢å¸§ä¸º numpy æ•°ç»„
                frames_np = []
                for frame in self.camera_frames:
                    frames_np.append(np.array(frame))
                
                # ä¿å­˜è§†é¢‘
                imageio.mimsave(video_path, frames_np, fps=fps, codec='libx264', quality=8)
                print(f"âœ… Video saved: {video_path}")
                messagebox.showinfo("Success", f"Video saved:\n{video_path}")
                
            except Exception as e:
                print(f"âŒ Error saving video: {e}")
                messagebox.showerror("Error", f"Failed to save video:\n{str(e)}")
        
        # ä¿å­˜éŸ³é¢‘ï¼ˆå¦‚æœæœ‰éŸ³ç¬¦è®°å½•ï¼‰
        if len(self.camera_audio_notes) > 0:
            audio_path = filedialog.asksaveasfilename(
                defaultextension=".wav",
                filetypes=[("WAV Audio", "*.wav"), ("All Files", "*.*")],
                title="Save Camera Audio"
            )
            
            if audio_path:
                try:
                    # TODO: å®ç°éŸ³é¢‘ä¿å­˜é€»è¾‘
                    print(f"âœ… Audio saved: {audio_path}")
                except Exception as e:
                    print(f"âŒ Error saving audio: {e}")
    
    def reload_camera(self):
        """é‡æ–°åŠ è½½æ‘„åƒå¤´ï¼ˆæ¸…ç©ºå½•åˆ¶ï¼‰"""
        if hasattr(self, 'camera_active') and self.camera_active:
            self.camera_frames = []
            self.camera_audio_notes = []
            self.camera_octave_shift = 0
            self.camera_speed = 1.0
            self.camera_paused = False
            print("ğŸ”„ Camera reloaded - recording cleared")
            messagebox.showinfo("Reloaded", "Recording cleared!\nCamera reset to default settings.")
    
    def play_camera_audio(self, img):
        """æ ¹æ®æ‘„åƒå¤´ç”»é¢é¢œè‰²å®æ—¶ç”Ÿæˆå£°éŸ³ï¼ˆä½¿ç”¨ä¸å›¾ç‰‡å¤„ç†ç›¸åŒçš„HSVé€»è¾‘ï¼‰"""
        # é‡‡æ ·ä¸­å¿ƒåŒºåŸŸçš„å¤šä¸ªç‚¹ï¼ˆé¿å…æ€§èƒ½é—®é¢˜ï¼‰
        width, height = img.size
        sample_points = []
        
        # åœ¨ä¸­å¿ƒåŒºåŸŸé‡‡æ · 3x3 ç½‘æ ¼ï¼ˆ9ä¸ªç‚¹ï¼Œå‡å°‘è®¡ç®—é‡ï¼‰
        center_x, center_y = width // 2, height // 2
        grid_size = 3
        spacing = 60
        
        for i in range(grid_size):
            for j in range(grid_size):
                x = center_x + (i - grid_size // 2) * spacing
                y = center_y + (j - grid_size // 2) * spacing
                
                # ç¡®ä¿åœ¨å›¾åƒèŒƒå›´å†…
                if 0 <= x < width and 0 <= y < height:
                    sample_points.append((x, y))
        
        # æ”¶é›†æ‰€æœ‰é‡‡æ ·ç‚¹çš„RGBå€¼
        rgb_values = []
        for x, y in sample_points:
            pixel_color = img.getpixel((x, y))
            r, g, b = pixel_color[:3] if len(pixel_color) >= 3 else (pixel_color[0], pixel_color[0], pixel_color[0])
            rgb_values.append((r, g, b))
        
        # è®¡ç®—å¹³å‡RGBï¼ˆæ›´å¹³æ»‘çš„éŸ³é¢‘ï¼‰
        if rgb_values:
            avg_r = sum(rgb[0] for rgb in rgb_values) / len(rgb_values)
            avg_g = sum(rgb[1] for rgb in rgb_values) / len(rgb_values)
            avg_b = sum(rgb[2] for rgb in rgb_values) / len(rgb_values)
            
            # ğŸµ ä½¿ç”¨ä¸å›¾ç‰‡å¤„ç†ç›¸åŒçš„ HSV â†’ éŸ³ç¬¦è½¬æ¢é€»è¾‘
            pitch, duration, velocity = self.melody_generator.rgba_to_note(
                int(avg_r), int(avg_g), int(avg_b), 255
            )
            
            # åº”ç”¨å…«åº¦åç§»
            pitch += self.camera_octave_shift
            pitch = max(21, min(108, pitch))  # é™åˆ¶åœ¨é’¢ç´éŸ³åŸŸå†…
            
            # è®°å½•éŸ³ç¬¦ï¼ˆç”¨äºå¯¼å‡ºï¼‰
            if self.camera_recording and not self.camera_paused:
                self.camera_audio_notes.append({
                    'pitch': pitch,
                    'duration': duration,
                    'velocity': velocity,
                    'rgb': (int(avg_r), int(avg_g), int(avg_b))
                })
            
            # ğŸµ æ’­æ”¾çŸ­ä¿ƒçš„éŸ³ç¬¦ï¼ˆå®æ—¶åé¦ˆï¼‰
            # åªåœ¨éŸ³é‡è¶³å¤Ÿå¤§æ—¶æ’­æ”¾ï¼ˆé¿å…é™éŸ³åŒºåŸŸäº§ç”Ÿå™ªéŸ³ï¼‰
            if velocity > 30:  # velocity é˜ˆå€¼
                try:
                    # ä½¿ç”¨ melody_generator çš„æ’­æ”¾æ–¹æ³•ï¼Œä½†æŒç»­æ—¶é—´å¾ˆçŸ­
                    self.melody_generator.play_note_direct(pitch, 0.05, velocity)
                except Exception as e:
                    # é™é»˜å¤±è´¥ï¼Œé¿å…å¹²æ‰°å®æ—¶é¢„è§ˆ
                    pass
    
    def capture_camera_frame(self):
        """æ•è·å½“å‰æ‘„åƒå¤´å¸§å¹¶å¼€å§‹å¤„ç†"""
        print("ğŸ¥ CAPTURE button clicked!")
        print(f"Camera frame exists: {self.camera_frame is not None}")
        
        if self.camera_frame is not None:
            # åœæ­¢æ‘„åƒå¤´
            self.camera_active = False
            if hasattr(self, 'camera_cap') and self.camera_cap.isOpened():
                self.camera_cap.release()
            
            # ç§»é™¤æ‘„åƒå¤´æ§åˆ¶æŒ‰é’®
            self.image_canvas.delete("camera_control")
            
            # ä¿å­˜æ•è·çš„å›¾ç‰‡
            self.current_image = Image.fromarray(self.camera_frame)
            self.current_image_path = "camera_capture"
            
            print(f"âœ… Image captured: {self.current_image.size}")
            print("ğŸ¨ Calling show_start_animation_popup()...")
            
            # æ˜¾ç¤ºå¹¶å¼€å§‹å¤„ç†
            self.display_image(self.current_image)
            self.show_start_animation_popup()
        else:
            print("âŒ No camera frame available!")
    
    def cancel_camera(self):
        """å–æ¶ˆæ‘„åƒå¤´æ•è·ï¼Œè¿”å›åŠ è½½ç•Œé¢"""
        # åœæ­¢æ‘„åƒå¤´
        self.camera_active = False
        if hasattr(self, 'camera_cap') and self.camera_cap.isOpened():
            self.camera_cap.release()
        
        # ç§»é™¤æ‘„åƒå¤´æ§åˆ¶æŒ‰é’®
        self.image_canvas.delete("camera_control")
        
        # è§£ç»‘é”®ç›˜æ§åˆ¶
        self.unbind_camera_keyboard_controls()
        
        # åœæ­¢å£°éŸ³
        try:
            pygame.mixer.stop()
        except:
            pass
        
        # è¿”å›åŠ è½½ç•Œé¢
        self.draw_load_button()
        self.status_canvas.itemconfig(self.status_text_id,
            text="[ READY ] Load image to start")
    
    def unbind_camera_keyboard_controls(self):
        """è§£ç»‘æ‘„åƒå¤´æ¨¡å¼çš„é”®ç›˜æ§åˆ¶"""
        try:
            self.root.unbind('w')
            self.root.unbind('W')
            self.root.unbind('s')
            self.root.unbind('S')
            self.root.unbind('a')
            self.root.unbind('A')
            self.root.unbind('d')
            self.root.unbind('D')
            self.root.unbind('<Up>')
            self.root.unbind('<Down>')
            self.root.unbind('<Left>')
            self.root.unbind('<Right>')
            self.root.unbind('<space>')
        except:
            pass
    
    def show_start_animation_popup(self):
        """Show Mac OS Classic style start animation popup"""
        popup = tk.Toplevel(self.root)
        popup.title("Scrapbook")
        popup.geometry("450x280")
        popup.configure(bg=self.bg_black)
        popup.resizable(False, False)
        popup.transient(self.root)
        popup.grab_set()
        
        # ç»‘å®š Enter é”®ç¡®è®¤
        popup.bind('<Return>', lambda e: self.confirm_start_animation(popup))
        popup.bind('<Escape>', lambda e: self.cancel_animation(popup))
        
        # Macé£æ ¼è¾¹æ¡†
        border_frame = tk.Frame(popup, bg=self.primary_pink, bd=3, relief=tk.RIDGE)
        border_frame.pack(fill=tk.BOTH, expand=True, padx=4, pady=4)
        
        inner_frame = tk.Frame(border_frame, bg=self.hover_beige, bd=2)
        inner_frame.pack(fill=tk.BOTH, expand=True, padx=2, pady=2)
        
        # æ ‡é¢˜
        title = tk.Label(
            inner_frame,
            text="IMAGE LOADED",
            font=self.pixel_font_large,
            bg=self.hover_beige,
            fg=self.bg_black
        )
        title.pack(pady=25)
        
        info_text = f"Size: {self.current_image.size[0]} x {self.current_image.size[1]} px\\n\\n"
        info_text += "Ready to pixelate and generate melody!\\n\\n"
        info_text += "Each pixel will play a note in real-time."
        
        info = tk.Label(
            inner_frame,
            text=info_text,
            font=self.pixel_font_small,
            bg=self.hover_beige,
            fg=self.bg_black,
            justify=tk.CENTER
        )
        info.pack(pady=15)
        
        # æç¤ºæ–‡å­—
        hint = tk.Label(
            inner_frame,
            text="Press ENTER to start or ESC to cancel",
            font=self.pixel_font_small,
            bg=self.hover_beige,
            fg=self.primary_pink
        )
        hint.pack(pady=5)
        
        button_frame = tk.Frame(inner_frame, bg=self.hover_beige)
        button_frame.pack(pady=25)
        
        # ç»Ÿä¸€æŒ‰é’®æ ·å¼å‚æ•°ï¼ˆä½¿ç”¨å­—ç¬¦å•ä½ï¼‰
        button_config = {
            'font': self.pixel_font_medium,
            'bg': self.hover_beige,
            'fg': self.bg_black,
            'activebackground': self.primary_pink,
            'activeforeground': self.bg_black,
            'bd': 3,
            'relief': tk.RAISED,
            'cursor': 'hand2',
            'width': 14,  # å­—ç¬¦å®½åº¦
            'height': 2   # è¡Œé«˜
        }
        
        # STARTæŒ‰é’® - Macé£æ ¼ï¼ˆç»Ÿä¸€å°ºå¯¸ï¼‰
        confirm_btn = tk.Button(
            button_frame,
            text="START",
            command=lambda: self.confirm_start_animation(popup),
            **button_config
        )
        confirm_btn.pack(side=tk.LEFT, padx=10)
        
        # CANCELæŒ‰é’®ï¼ˆç»Ÿä¸€å°ºå¯¸ï¼‰
        cancel_btn = tk.Button(
            button_frame,
            text="CANCEL",
            command=lambda: self.cancel_animation(popup),
            **button_config
        )
        cancel_btn.pack(side=tk.LEFT, padx=10)
    
    def cancel_animation(self, popup):
        """Cancel animation and return to load screen"""
        popup.destroy()
        # æ¸…ç©ºå½“å‰å›¾ç‰‡
        self.current_image_path = None
        self.current_image = None
        self.pixelated_image = None
        # é‡æ–°æ˜¾ç¤º LOAD æŒ‰é’®ç•Œé¢
        self.draw_load_button()
        self.status_canvas.itemconfig(self.status_text_id,
            text="[ READY ] Load image to start")
    
    def confirm_start_animation(self, popup):
        """Confirm start animation"""
        popup.destroy()
        self.start_pixelation_animation()
    
    def display_image(self, image):
        """Display image"""
        self.image_canvas.delete("all")
        
        self.image_canvas.update()
        canvas_width = self.image_canvas.winfo_width()
        canvas_height = self.image_canvas.winfo_height()
        
        if canvas_width <= 1:
            canvas_width = 800
        if canvas_height <= 1:
            canvas_height = 500
        
        img_copy = image.copy()
        img_copy.thumbnail((canvas_width - 20, canvas_height - 20), Image.Resampling.LANCZOS)
        
        self.photo_image = ImageTk.PhotoImage(img_copy)
        
        x = (canvas_width - self.photo_image.width()) // 2
        y = (canvas_height - self.photo_image.height()) // 2
        self.image_canvas.create_image(x, y, anchor=tk.NW, image=self.photo_image)
    
    def start_pixelation_animation(self):
        """Start pixelation animation with original colors - extract top-left pixel of each 40Ã—40 block"""
        if not self.current_image_path:
            return
        
        try:
            # æ¸…ç©ºä¹‹å‰å½•åˆ¶çš„éŸ³ç¬¦å’ŒåŠ¨ç”»å¸§
            self.melody_generator.clear_recorded_notes()
            self.animation_frames = []
            self.frame_timestamps = []
            self.is_recording = True  # å¯ç”¨å½•åˆ¶
            
            self.status_canvas.itemconfig(self.status_text_id, 
                                         text="[ INITIALIZING ] Preparing animation...")
            self.root.update()
            
            print(f"Loading image: {self.current_image_path}")
            img = Image.open(self.current_image_path)
            print(f"Image loaded: {img.size[0]}Ã—{img.size[1]}, mode: {img.mode}")
            
            # æ£€æµ‹æ˜¯å¦æœ‰é€æ˜åº¦é€šé“
            has_alpha = img.mode == 'RGBA'
            
            # è½¬æ¢ä¸ºRGBæˆ–RGBAï¼ˆä¿ç•™åŸå§‹é¢œè‰²ï¼‰
            if img.mode not in ['RGB', 'RGBA']:
                img = img.convert('RGB')
                has_alpha = False
            
            # å¦‚æœå›¾ç‰‡å¤ªå¤§ï¼Œç¼©å°åˆ°åˆç†å°ºå¯¸
            max_size = 800
            width, height = img.size
            if width > max_size or height > max_size:
                ratio = min(max_size / width, max_size / height)
                new_width = int(width * ratio)
                new_height = int(height * ratio)
                img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)
                print(f"âš  Large image resized: {width}Ã—{height} â†’ {new_width}Ã—{new_height}")
                width, height = new_width, new_height
            
            # ä¿å­˜åŸå§‹å›¾åƒç”¨äºéŸ³é¢‘è½¨
            original_img = img.copy()
            
            self.status_canvas.itemconfig(self.status_text_id, 
                                         text="[ PROCESSING ] Applying 1-bit pixelation...")
            self.root.update()
            
            # åº”ç”¨ 1-bit åƒç´ åŒ–ï¼ˆä¸‰è‰²ï¼‰ç”¨äºè§†è§‰è½¨
            pixelated_img = self.apply_1bit_pixelation(img)
            print("âœ“ 1-bit pixelation applied for visual track")
            
            self.status_canvas.itemconfig(self.status_text_id, 
                                         text="[ PROCESSING ] Creating pixel grid...")
            self.root.update()
            
            # ä½¿ç”¨åƒç´ åŒ–åçš„å›¾åƒå°ºå¯¸è®¡ç®—ç½‘æ ¼
            pixel_width, pixel_height = pixelated_img.size
            
            # è®¡ç®—ç½‘æ ¼å¤§å° (æ¯10Ã—10åƒç´ ä¸€ä¸ªå—)
            self.grid_width = max(1, pixel_width // self.pixel_size)
            self.grid_height = max(1, pixel_height // self.pixel_size)
            
            print(f"Grid size: {self.grid_width}Ã—{self.grid_height} = {self.grid_width * self.grid_height} blocks")
            
            # é™åˆ¶æœ€å¤§å—æ•°ï¼ˆå¢åŠ ä»¥æ˜¾ç¤ºæ›´å¤šåƒç´ ï¼‰
            max_blocks = 800  # ä» 300 å¢åŠ åˆ° 800
            total_blocks = self.grid_width * self.grid_height
            if total_blocks > max_blocks:
                scale_factor = (max_blocks / total_blocks) ** 0.5
                self.pixel_size = int(self.pixel_size / scale_factor)
                self.grid_width = max(1, pixel_width // self.pixel_size)
                self.grid_height = max(1, pixel_height // self.pixel_size)
                print(f"âš  Too many blocks, adjusted to: {self.grid_width}Ã—{self.grid_height} blocks")
            
            print("Extracting colors: visual from 1-bit, audio from original...")
            self.rgb_data_list = []
            
            # è®¡ç®—åŸå§‹å›¾åƒå’Œåƒç´ åŒ–å›¾åƒçš„ç¼©æ”¾æ¯”ä¾‹
            orig_width, orig_height = original_img.size
            scale_x = orig_width / pixel_width
            scale_y = orig_height / pixel_height
            
            # éå†æ¯ä¸ª10Ã—10å—
            for grid_y in range(self.grid_height):
                for grid_x in range(self.grid_width):
                    # åƒç´ åŒ–å›¾åƒçš„å·¦ä¸Šè§’åæ ‡ï¼ˆç”¨äºè§†è§‰ï¼‰
                    pixel_x = grid_x * self.pixel_size
                    pixel_y = grid_y * self.pixel_size
                    
                    # åŸå§‹å›¾åƒçš„å¯¹åº”åæ ‡ï¼ˆç”¨äºéŸ³é¢‘ï¼‰
                    orig_x = int(pixel_x * scale_x)
                    orig_y = int(pixel_y * scale_y)
                    
                    # ç¡®ä¿ä¸è¶Šç•Œ
                    if pixel_x < pixel_width and pixel_y < pixel_height:
                        # è§†è§‰è½¨ï¼šä»1-bitåƒç´ åŒ–å›¾åƒæå–é¢œè‰²
                        visual_pixel = pixelated_img.getpixel((pixel_x, pixel_y))
                        
                        # éŸ³é¢‘è½¨ï¼šä»åŸå§‹å›¾åƒæå–é¢œè‰²
                        if orig_x < orig_width and orig_y < orig_height:
                            audio_pixel = original_img.getpixel((orig_x, orig_y))
                        else:
                            audio_pixel = visual_pixel
                        
                        # å¤„ç†RGBA (1-bitå›¾åƒæ˜¯RGB)
                        visual_r, visual_g, visual_b = visual_pixel
                        visual_a = 255
                        
                        if has_alpha:
                            if isinstance(audio_pixel, tuple) and len(audio_pixel) == 4:
                                audio_r, audio_g, audio_b, audio_a = audio_pixel
                            else:
                                audio_r, audio_g, audio_b = audio_pixel
                                audio_a = 255
                        else:
                            if isinstance(audio_pixel, tuple) and len(audio_pixel) >= 3:
                                audio_r, audio_g, audio_b = audio_pixel[:3]
                            else:
                                audio_r = audio_g = audio_b = audio_pixel if isinstance(audio_pixel, int) else 0
                            audio_a = 255
                        
                        # å­˜å‚¨ï¼šè§†è§‰RGBAï¼ˆç”¨äºæ˜¾ç¤ºï¼‰+ éŸ³é¢‘RGBAï¼ˆç”¨äºæ—‹å¾‹ï¼‰+ ç½‘æ ¼åæ ‡
                        self.rgb_data_list.append((
                            int(visual_r), int(visual_g), int(visual_b), int(visual_a),  # è§†è§‰è½¨
                            int(audio_r), int(audio_g), int(audio_b), int(audio_a),      # éŸ³é¢‘è½¨
                            grid_x, grid_y
                        ))
            
            print(f"âœ“ Extracted {len(self.rgb_data_list)} blocks (visual: 1-bit, audio: original)")
            
            # åˆ›å»ºåƒç´ åŒ–å›¾åƒ
            pixelated_width = self.grid_width * self.pixel_size
            pixelated_height = self.grid_height * self.pixel_size
            mode = 'RGBA' if has_alpha else 'RGB'
            self.pixelated_image = Image.new(mode, (pixelated_width, pixelated_height), 
                                            color=(0, 0, 0, 255) if has_alpha else (0, 0, 0))
            
            self.current_pixel_index = 0
            self.is_animating = True
            self.animation_paused = False
            self.octave_shift = 0
            self.octave_canvas.itemconfig(self.octave_display_id, text="PITCH: +0")
            
            # Reset data moshing state and trace background
            self.glitch_frames = []
            self.moshing_intensity = 0.0
            self.trace_background = None  # é‡ç½®traceèƒŒæ™¯
            self.glitch_history = None  # é‡ç½®glitchå†å²å±‚
            
            self.status_canvas.itemconfig(self.status_text_id, 
                                         text="[ PLAYING ] Generating melody...")
            self.root.update()
            
            print("Starting animation: visual=1-bit pixel, audio=original...")
            self.animate_next_pixel()
            
        except Exception as e:
            import traceback
            error_msg = f"Failed to start animation: {str(e)}"
            print(f"âœ— {error_msg}")
            traceback.print_exc()
            messagebox.showerror("Error", error_msg)
    
    def animate_next_pixel(self):
        """Animate next pixel block with fade trace effects and play note with RGBA support"""
        if not self.is_animating or self.animation_paused:
            return
        
        if self.current_pixel_index >= len(self.rgb_data_list):
            self.finish_animation()
            return
        
        # åˆå§‹åŒ–traceèƒŒæ™¯ï¼ˆç¬¬ä¸€æ¬¡ï¼‰
        if self.trace_background is None:
            self.trace_background = Image.new(
                self.pixelated_image.mode, 
                self.pixelated_image.size, 
                color=(1, 1, 1, 0) if self.pixelated_image.mode == 'RGBA' else (1, 1, 1)
            )
        
        # åˆå§‹åŒ–glitchå†å²å±‚ï¼ˆç¬¬ä¸€æ¬¡ï¼‰
        if self.glitch_history is None:
            self.glitch_history = Image.new(
                'RGBA',
                self.pixelated_image.size,
                color=(0, 0, 0, 0)  # é€æ˜èƒŒæ™¯
            )
        
        # è§£åŒ…åŒè½¨æ•°æ®ï¼šè§†è§‰RGBA + éŸ³é¢‘RGBA + åæ ‡
        pixel_data = self.rgb_data_list[self.current_pixel_index]
        visual_r, visual_g, visual_b, visual_a, audio_r, audio_g, audio_b, audio_a, grid_x, grid_y = pixel_data
        
        # ç»˜åˆ¶åƒç´ å—åˆ°ä¸»å›¾åƒï¼ˆä½¿ç”¨éŸ³é¢‘è½¨çš„åŸå§‹é¢œè‰² + å¾®å¼±ç²’å­shiftæ•ˆæœï¼‰
        # æ³¨æ„ï¼šæ˜¾ç¤ºä½¿ç”¨åŸå§‹é¢œè‰²(audio)ï¼ŒéŸ³ä¹ä¹Ÿä½¿ç”¨åŸå§‹é¢œè‰²(audio)
        import random
        
        # è®¡ç®—å½“å‰å¸§çš„shiftåç§»ï¼ˆåŸºäºæ—¶é—´çš„å¾®å¼±æ³¢åŠ¨ï¼‰
        frame_offset = self.current_pixel_index % 60  # 60å¸§å¾ªç¯
        shift_x = int(random.random() * 2 - 1) if random.random() < 0.15 else 0  # 15%æ¦‚ç‡Â±1åƒç´ 
        shift_y = int(random.random() * 2 - 1) if random.random() < 0.10 else 0  # 10%æ¦‚ç‡Â±1åƒç´ 
        
        for py in range(self.pixel_size):
            for px in range(self.pixel_size):
                pixel_x = grid_x * self.pixel_size + px
                pixel_y = grid_y * self.pixel_size + py
                
                # æ·»åŠ å¾®å¼±çš„1-bitç²’å­æ•ˆæœï¼ˆéƒ¨åˆ†åƒç´ æœ‰è½»å¾®ä½ç§»ï¼‰
                use_shift = random.random() < 0.08  # 8%çš„åƒç´ æœ‰shiftæ•ˆæœ
                final_x = pixel_x + shift_x if use_shift else pixel_x
                final_y = pixel_y + shift_y if use_shift else pixel_y
                
                # è¾¹ç•Œæ£€æŸ¥
                if final_x < self.pixelated_image.size[0] and final_y < self.pixelated_image.size[1]:
                    if final_x >= 0 and final_y >= 0:
                        # ä½¿ç”¨éŸ³é¢‘è½¨çš„åŸå§‹é¢œè‰²è¿›è¡Œæ˜¾ç¤ºï¼ˆç¡®ä¿æ˜¾ç¤ºåŸå›¾çš„åƒç´ åŒ–æ•ˆæœï¼‰
                        r_int = int(audio_r)
                        g_int = int(audio_g)
                        b_int = int(audio_b)
                        a_int = int(audio_a)
                        
                        # å¾®å¼±çš„é¢œè‰²æŠ–åŠ¨ï¼ˆ1-bité£æ ¼ï¼‰- æå°‘æ•°åƒç´ 
                        if random.random() < 0.03:  # 3%æ¦‚ç‡
                            # åœ¨è°ƒè‰²æ¿ä¸­éšæœºé€‰æ‹©ç›¸é‚»é¢œè‰²
                            color_shift = random.choice([
                                (r_int, g_int, b_int),  # åŸè‰²
                                (max(0, r_int - 20), max(0, g_int - 10), max(0, b_int - 15)),  # ç¨æš—
                                (min(255, r_int + 15), min(255, g_int + 10), min(255, b_int + 10))  # ç¨äº®
                            ])
                            r_int, g_int, b_int = color_shift
                        
                        # ç»˜åˆ¶åˆ°ä¸»å›¾åƒå’ŒtraceèƒŒæ™¯
                        if self.pixelated_image.mode == 'RGBA':
                            self.pixelated_image.putpixel((final_x, final_y), (r_int, g_int, b_int, a_int))
                            # traceèƒŒæ™¯ä¸å—shiftå½±å“
                            if pixel_x < self.pixelated_image.size[0] and pixel_y < self.pixelated_image.size[1]:
                                self.trace_background.putpixel((pixel_x, pixel_y), (r_int, g_int, b_int, 255))
                        else:
                            self.pixelated_image.putpixel((final_x, final_y), (r_int, g_int, b_int))
                            if pixel_x < self.pixelated_image.size[0] and pixel_y < self.pixelated_image.size[1]:
                                self.trace_background.putpixel((pixel_x, pixel_y), (r_int, g_int, b_int))
        
        # åº”ç”¨æ¸æ·¡æ•ˆæœåˆ°traceèƒŒæ™¯ï¼ˆæ¯ä¸ªåƒç´ é€æ˜åº¦é™ä½ï¼‰
        if self.pixelated_image.mode == 'RGBA':
            trace_pixels = self.trace_background.load()
            width, height = self.trace_background.size
            for y in range(height):
                for x in range(width):
                    r, g, b, a = trace_pixels[x, y]
                    # é€æ¸é™ä½é€æ˜åº¦ï¼ˆæ¸æ·¡æ•ˆæœï¼‰
                    new_a = max(0, int(a * 0.95))  # æ¯å¸§é™ä½5%
                    trace_pixels[x, y] = (r, g, b, new_a)
        
        # Calculate progressive data moshing intensity
        progress = (self.current_pixel_index + 1) / len(self.rgb_data_list)
        
        # æ›´å¼ºçƒˆçš„ glitch å¼ºåº¦æ›²çº¿ï¼ˆå‚è€ƒ fauux.neocities.org/glimmer é£æ ¼ï¼‰
        if progress < 0.5:
            self.moshing_intensity = progress * 0.6  # å‰åŠæ®µå¿«é€Ÿå¢å¼ºåˆ° 0.3
        elif progress < 0.8:
            self.moshing_intensity = 0.3 + (progress - 0.5) * 0.4  # ä¸­æ®µç»§ç»­å¢å¼ºåˆ° 0.42
        else:
            self.moshing_intensity = 0.42 * (1.0 - (progress - 0.8) / 0.2)  # æœ€åæ¸å¼±
        
        # åˆæˆæœ€ç»ˆå›¾åƒï¼štraceèƒŒæ™¯ + å½“å‰åƒç´ åŒ–å›¾åƒ
        final_image = self.trace_background.copy()
        if self.pixelated_image.mode == 'RGBA':
            final_image = Image.alpha_composite(final_image, self.pixelated_image)
        else:
            final_image.paste(self.pixelated_image, (0, 0))
        
        # æ›´é¢‘ç¹åœ°åº”ç”¨ glitch æ•ˆæœï¼ˆæ¯2å¸§è€Œä¸æ˜¯5å¸§ï¼‰ï¼Œå¹¶ç´¯ç§¯åˆ°å†å²å±‚
        if self.current_pixel_index % 2 == 0 and self.moshing_intensity > 0.05:
            # ç”Ÿæˆglitchæ•ˆæœ
            glitch_frame = self.apply_data_moshing(final_image.copy(), self.moshing_intensity)
            
            # å°†glitchæ•ˆæœæå–å‡ºæ¥ï¼ˆåªä¿ç•™glitchéƒ¨åˆ†ï¼Œå»æ‰åŸå›¾ï¼‰
            # åˆ›å»ºä¸€ä¸ªåªåŒ…å«glitch artifactsçš„å›¾å±‚
            if glitch_frame.mode != 'RGBA':
                glitch_frame = glitch_frame.convert('RGBA')
            
            # ç´¯ç§¯åˆ°glitchå†å²å±‚ï¼ˆalphaæ··åˆï¼‰
            self.glitch_history = Image.alpha_composite(self.glitch_history, glitch_frame)
            
            # å¯é€‰ï¼šè®©å†å²å±‚é€æ¸æ·¡åŒ–ï¼ˆå¦‚æœå¸Œæœ›æ—§çš„glitchæ…¢æ…¢æ¶ˆå¤±ï¼‰
            # å–æ¶ˆä¸‹é¢çš„æ³¨é‡Šæ¥å¯ç”¨æ·¡åŒ–æ•ˆæœ
            # glitch_pixels = self.glitch_history.load()
            # width, height = self.glitch_history.size
            # for y in range(height):
            #     for x in range(width):
            #         r, g, b, a = glitch_pixels[x, y]
            #         new_a = max(0, int(a * 0.98))  # æ¯å¸§é™ä½2%ï¼ˆæ¯”traceæ…¢ï¼‰
            #         glitch_pixels[x, y] = (r, g, b, new_a)
        
        # åˆæˆæ‰€æœ‰å±‚ï¼šfinal_image + glitch_history
        if self.glitch_history.mode == 'RGBA':
            final_image = Image.alpha_composite(final_image.convert('RGBA'), self.glitch_history)
        
        # æ·»åŠ å¾®å¼±çš„æ•´ä½“ç”»é¢shiftæ•ˆæœï¼ˆwiredfriendé£æ ¼ï¼‰
        if random.random() < 0.20:  # 20%æ¦‚ç‡å‡ºç°æ•´ä½“æŠ–åŠ¨
            final_image = self.apply_subtle_shift(final_image)
        
        self.display_image(final_image)
        
        # å¦‚æœæ­£åœ¨å½•åˆ¶ï¼Œä¿å­˜å½“å‰å¸§
        if self.is_recording:
            import time
            self.animation_frames.append(final_image.copy())
            self.frame_timestamps.append(time.time())
        
        # ä½¿ç”¨éŸ³é¢‘è½¨çš„åŸå§‹é¢œè‰²æ’­æ”¾éŸ³ç¬¦
        threading.Thread(target=self.play_note_for_pixel, args=(audio_r, audio_g, audio_b, audio_a), daemon=True).start()
        
        # è®¡ç®—HSVç”¨äºæ˜¾ç¤ºï¼ˆä»éŸ³é¢‘è½¨çš„åŸå§‹é¢œè‰²ï¼‰
        h, s, v = self.melody_generator.rgb_to_hsv(audio_r, audio_g, audio_b)
        
        # Update status with glitch indicator and HSV info
        glitch_indicator = "âš¡" if self.moshing_intensity > 0.1 else ""
        self.status_canvas.itemconfig(self.status_text_id,
            text=f"[ PLAYING ] {glitch_indicator} Block ({grid_x},{grid_y}) RGB({audio_r},{audio_g},{audio_b}) HSV({h:.1f}Â°,{s:.1f}%,{v:.1f}%) | {self.current_pixel_index+1}/{len(self.rgb_data_list)} | {progress*100:.1f}%"
        )
        
        self.current_pixel_index += 1
        
        # åŠ¨ç”»é€Ÿåº¦æ§åˆ¶ï¼ˆåŸºäºéŸ³é¢‘è½¨é¢œè‰² + é€Ÿåº¦å€ç‡ï¼‰
        base_duration = int(50 + (audio_g / 255.0) * 20)  # åŸºç¡€ 50-70ms
        
        # ä¸­é—´æ®µåŠ å¿«ï¼ˆ30%-70%è¿›åº¦æ—¶é€Ÿåº¦åŠ å€ï¼‰
        if 0.3 <= progress <= 0.7:
            base_duration = int(base_duration * 0.5)  # ä¸­é—´æ®µå¿«2å€
        
        # åº”ç”¨ç”¨æˆ·æ§åˆ¶çš„é€Ÿåº¦å€ç‡
        duration_ms = int(base_duration * self.speed_multiplier)
        
        self.root.after(duration_ms, self.animate_next_pixel)
    
    def play_note_for_pixel(self, r, g, b, a=255):
        """Play 8-bit style note for single pixel with HSV-based RGBA support"""
        try:
            # ä½¿ç”¨HSV-based RGBAç”ŸæˆéŸ³ç¬¦
            pitch, duration, velocity = self.melody_generator.rgba_to_note(r, g, b, a)
            pitch += self.octave_shift
            pitch = max(21, min(108, pitch))
            
            # è®°å½•éŸ³ç¬¦ç”¨äºä¿å­˜
            self.melody_generator.recorded_notes.append({
                'pitch': pitch,
                'duration': duration,
                'velocity': velocity,
                'rgb': (r, g, b, a)
            })
            
            # ç›´æ¥æ’­æ”¾æ³¢å½¢éŸ³é¢‘ï¼ˆæ— éœ€MIDIè®¾å¤‡ï¼‰
            self.melody_generator.play_note_direct(pitch, duration, velocity)
            
            # è°ƒè¯•è¾“å‡º
            if self.current_pixel_index % 10 == 0:
                h, s, v = self.melody_generator.rgb_to_hsv(r, g, b)
                print(f"Note: RGB({r},{g},{b}) â†’ HSV({h:.2f},{s:.2f},{v:.2f}) â†’ Pitch={pitch}, Vel={velocity}")
            
        except Exception as e:
            if self.current_pixel_index == 0:
                print(f"âœ— Error playing note: {e}")
            pass
    
    def finish_animation(self):
        """Finish animation and show save options"""
        self.is_animating = False
        self.animation_paused = False
        
        # åœæ­¢æ‰€æœ‰æ­£åœ¨æ’­æ”¾çš„å£°éŸ³
        try:
            pygame.mixer.stop()
        except:
            pass
        
        total_notes = len(self.melody_generator.recorded_notes)
        total_frames = len(self.animation_frames) if self.animation_frames else 0
        
        print(f"\nğŸ¬ Animation Complete:")
        print(f"   Notes recorded: {total_notes}")
        print(f"   Frames recorded: {total_frames}")
        print(f"   Recording was: {'ON' if self.is_recording else 'OFF'}")
        
        self.status_canvas.itemconfig(self.status_text_id,
            text=f"[ COMPLETE ] Generated {total_notes} notes, {total_frames} frames | EXPORT OPTIONS")
        
        self.image_canvas.update()
        canvas_width = self.image_canvas.winfo_width()
        canvas_height = self.image_canvas.winfo_height()
        
        # è®¡ç®—æŒ‰é’®å¸ƒå±€ï¼ˆæ ¹æ®æ˜¯å¦æœ‰è§†é¢‘å¸§åŠ¨æ€è°ƒæ•´ï¼‰
        button_width = 110
        button_height = 50
        button_spacing = 20
        y_pos = canvas_height // 2 - 100  # å‚ç›´ä½ç½®
        
        # ç¡®å®šè¦æ˜¾ç¤ºçš„æŒ‰é’®æ•°é‡
        has_video = bool(self.animation_frames)
        num_buttons = 4 if has_video else 3  # MIDI, VIDEO(å¯é€‰), AUDIO, NEW
        
        # è®¡ç®—æ€»å®½åº¦å¹¶å±…ä¸­
        total_width = num_buttons * button_width + (num_buttons - 1) * button_spacing
        start_x = (canvas_width - total_width) // 2
        
        # å½“å‰æŒ‰é’®xä½ç½®
        current_x = start_x
        
        # MIDIæŒ‰é’®
        self.image_canvas.create_rectangle(
            current_x, y_pos,
            current_x + button_width, y_pos + button_height,
            fill=self.hover_beige,
            outline=self.primary_pink,
            width=3,
            tags="save_button"
        )
        
        self.image_canvas.create_text(
            current_x + button_width // 2, y_pos + button_height // 2,
            text="MIDI",
            font=self.pixel_font_small,
            fill=self.bg_black,
            tags="save_button"
        )
        current_x += button_width + button_spacing
        
        # VIDEOæŒ‰é’®ï¼ˆå¦‚æœæœ‰å½•åˆ¶å¸§ï¼‰
        if has_video:
            self.image_canvas.create_rectangle(
                current_x, y_pos,
                current_x + button_width, y_pos + button_height,
                fill=self.hover_beige,
                outline=self.primary_pink,
                width=3,
                tags="export_video_button"
            )
            
            self.image_canvas.create_text(
                current_x + button_width // 2, y_pos + button_height // 2,
                text="VIDEO",
                font=self.pixel_font_small,
                fill=self.bg_black,
                tags="export_video_button"
            )
            current_x += button_width + button_spacing
        
        # AUDIOæŒ‰é’®
        self.image_canvas.create_rectangle(
            current_x, y_pos,
            current_x + button_width, y_pos + button_height,
            fill=self.hover_beige,
            outline=self.primary_pink,
            width=3,
            tags="export_audio_button"
        )
        
        self.image_canvas.create_text(
            current_x + button_width // 2, y_pos + button_height // 2,
            text="AUDIO",
            font=self.pixel_font_small,
            fill=self.bg_black,
            tags="export_audio_button"
        )
        current_x += button_width + button_spacing
        
        # NEWæŒ‰é’®
        self.image_canvas.create_rectangle(
            current_x, y_pos,
            current_x + button_width, y_pos + button_height,
            fill=self.hover_beige,
            outline=self.primary_pink,
            width=3,
            tags="reload_button"
        )
        
        self.image_canvas.create_text(
            current_x + button_width // 2, y_pos + button_height // 2,
            text="NEW",
            font=self.pixel_font_small,
            fill=self.bg_black,
            tags="reload_button"
        )
        
        # ç»‘å®šä¿å­˜æŒ‰é’®ç‚¹å‡»å’Œå…‰æ ‡æ•ˆæœ
        self.image_canvas.tag_bind("save_button", "<Button-1>", lambda e: self.save_melody())
        self.image_canvas.tag_bind("save_button", "<Enter>", self.on_save_button_enter)
        self.image_canvas.tag_bind("save_button", "<Leave>", self.on_save_button_leave)
        
        # ç»‘å®šå¯¼å‡ºè§†é¢‘æŒ‰é’®
        if self.animation_frames:
            self.image_canvas.tag_bind("export_video_button", "<Button-1>", lambda e: self.export_video())
            self.image_canvas.tag_bind("export_video_button", "<Enter>", self.on_export_video_button_enter)
            self.image_canvas.tag_bind("export_video_button", "<Leave>", self.on_export_video_button_leave)
        
        # ç»‘å®šå¯¼å‡ºéŸ³é¢‘æŒ‰é’®
        self.image_canvas.tag_bind("export_audio_button", "<Button-1>", lambda e: self.export_audio())
        self.image_canvas.tag_bind("export_audio_button", "<Enter>", self.on_export_audio_button_enter)
        self.image_canvas.tag_bind("export_audio_button", "<Leave>", self.on_export_audio_button_leave)
        
        # ç»‘å®š LOAD NEW æŒ‰é’®ç‚¹å‡»å’Œå…‰æ ‡æ•ˆæœ
        self.image_canvas.tag_bind("reload_button", "<Button-1>", lambda e: self.reset_and_load())
        self.image_canvas.tag_bind("reload_button", "<Enter>", self.on_reload_button_enter)
        self.image_canvas.tag_bind("reload_button", "<Leave>", self.on_reload_button_leave)
    
    def on_save_button_enter(self, event):
        """é¼ æ ‡è¿›å…¥ Save æŒ‰é’®æ—¶é«˜äº®"""
        items = self.image_canvas.find_withtag("save_button")
        if items:
            self.image_canvas.itemconfig(items[0], fill=self.primary_pink)  # çŸ©å½¢å˜ç²‰è‰²
        self.image_canvas.config(cursor="hand2")
    
    def on_save_button_leave(self, event):
        """é¼ æ ‡ç¦»å¼€ Save æŒ‰é’®æ—¶æ¢å¤"""
        items = self.image_canvas.find_withtag("save_button")
        if items:
            self.image_canvas.itemconfig(items[0], fill=self.hover_beige)  # æ¢å¤ç±³è‰²
        self.image_canvas.config(cursor="")
    
    def on_reload_button_enter(self, event):
        """é¼ æ ‡è¿›å…¥ Load New æŒ‰é’®æ—¶é«˜äº®"""
        items = self.image_canvas.find_withtag("reload_button")
        if items:
            self.image_canvas.itemconfig(items[0], fill=self.primary_pink)  # çŸ©å½¢å˜ç²‰è‰²
        self.image_canvas.config(cursor="hand2")
    
    def on_reload_button_leave(self, event):
        """é¼ æ ‡ç¦»å¼€ Load New æŒ‰é’®æ—¶æ¢å¤"""
        items = self.image_canvas.find_withtag("reload_button")
        if items:
            self.image_canvas.itemconfig(items[0], fill=self.hover_beige)  # æ¢å¤ç±³è‰²
        self.image_canvas.config(cursor="")
    
    def on_export_video_button_enter(self, event):
        """é¼ æ ‡è¿›å…¥ Export Video æŒ‰é’®æ—¶é«˜äº®"""
        items = self.image_canvas.find_withtag("export_video_button")
        if items:
            self.image_canvas.itemconfig(items[0], fill=self.primary_pink)
        self.image_canvas.config(cursor="hand2")
    
    def on_export_video_button_leave(self, event):
        """é¼ æ ‡ç¦»å¼€ Export Video æŒ‰é’®æ—¶æ¢å¤"""
        items = self.image_canvas.find_withtag("export_video_button")
        if items:
            self.image_canvas.itemconfig(items[0], fill=self.hover_beige)
        self.image_canvas.config(cursor="")
    
    def on_export_audio_button_enter(self, event):
        """é¼ æ ‡è¿›å…¥ Export Audio æŒ‰é’®æ—¶é«˜äº®"""
        items = self.image_canvas.find_withtag("export_audio_button")
        if items:
            self.image_canvas.itemconfig(items[0], fill=self.primary_pink)
        self.image_canvas.config(cursor="hand2")
    
    def on_export_audio_button_leave(self, event):
        """é¼ æ ‡ç¦»å¼€ Export Audio æŒ‰é’®æ—¶æ¢å¤"""
        items = self.image_canvas.find_withtag("export_audio_button")
        if items:
            self.image_canvas.itemconfig(items[0], fill=self.hover_beige)
        self.image_canvas.config(cursor="")
    
    def save_melody(self):
        """ä¿å­˜ç”Ÿæˆçš„æ—‹å¾‹ä¸ºMIDIæ–‡ä»¶"""
        if not self.melody_generator.recorded_notes:
            messagebox.showwarning("No Melody", "No melody to save!")
            return
        
        file_path = filedialog.asksaveasfilename(
            title="Save Melody",
            defaultextension=".mid",
            filetypes=[
                ("MIDI Files", "*.mid"),
                ("All Files", "*.*")
            ]
        )
        
        if file_path:
            try:
                # ç¡®ä¿æ–‡ä»¶æ‰©å±•åæ˜¯ .mid
                if not file_path.lower().endswith('.mid'):
                    file_path += '.mid'
                
                self.melody_generator.save_recorded_melody(file_path)
                messagebox.showinfo("Success", f"Melody saved successfully!\n\n{len(self.melody_generator.recorded_notes)} notes saved to:\n{file_path}")
                self.status_canvas.itemconfig(self.status_text_id,
                    text=f"[ SAVED ] Melody saved to {os.path.basename(file_path)}")
            except Exception as e:
                import traceback
                traceback.print_exc()
                messagebox.showerror("Error", f"Failed to save melody: {str(e)}")
    
    def export_video(self):
        """å¯¼å‡ºè§†é¢‘ï¼ˆåŒ…å«éŸ³é¢‘ï¼‰"""
        if not self.animation_frames:
            messagebox.showwarning("No Video", "No animation frames to export!\n\nFrames are only recorded during animation playback.")
            return
        
        print(f"ğŸ“¹ Starting video export: {len(self.animation_frames)} frames")
        
        file_path = filedialog.asksaveasfilename(
            title="Export Video",
            defaultextension=".mp4",
            filetypes=[
                ("MP4 Video", "*.mp4"),
                ("AVI Video", "*.avi"),
                ("All Files", "*.*")
            ]
        )
        
        if file_path:
            try:
                import numpy as np
                
                # æ£€æŸ¥æ˜¯å¦å®‰è£…äº† imageio
                try:
                    import imageio
                    print(f"âœ“ imageio loaded: {imageio.__version__}")
                except ImportError:
                    print("âœ— imageio not installed")
                    messagebox.showerror("Error", "imageio library is required for video export.\n\nInstall with:\npip install imageio imageio-ffmpeg")
                    return
                
                self.status_canvas.itemconfig(self.status_text_id,
                    text="[ EXPORTING ] Rendering video...")
                self.root.update()
                
                # è®¡ç®—å¸§ç‡ï¼ˆåŸºäºæ—¶é—´æˆ³ï¼‰
                if len(self.frame_timestamps) > 1:
                    avg_frame_time = (self.frame_timestamps[-1] - self.frame_timestamps[0]) / len(self.frame_timestamps)
                    fps = int(1.0 / max(avg_frame_time, 0.016))  # æœ€å°16ms = 60fps
                    fps = max(10, min(fps, 60))  # é™åˆ¶åœ¨ 10-60 fps
                else:
                    fps = 30
                
                print(f"ğŸ“Š Video settings: {len(self.animation_frames)} frames @ {fps} FPS")
                
                # è½¬æ¢PILå›¾åƒä¸ºnumpyæ•°ç»„
                video_frames = []
                for i, frame in enumerate(self.animation_frames):
                    if i % 100 == 0:
                        print(f"  Converting frame {i+1}/{len(self.animation_frames)}...")
                    if frame.mode != 'RGB':
                        frame = frame.convert('RGB')
                    video_frames.append(np.array(frame))
                
                print(f"ğŸ’¾ Saving to: {file_path}")
                
                # ä¿å­˜è§†é¢‘ï¼ˆä¸åŒ…å«éŸ³é¢‘ï¼‰
                imageio.mimsave(file_path, video_frames, fps=fps, codec='libx264')
                
                print(f"âœ… Video exported successfully!")
                
                messagebox.showinfo("Success", 
                    f"Video exported successfully!\n\n"
                    f"Frames: {len(self.animation_frames)}\n"
                    f"FPS: {fps}\n"
                    f"Duration: {len(self.animation_frames)/fps:.2f}s\n"
                    f"File: {file_path}\n\n"
                    f"Note: Export audio separately and combine in video editor if needed.")
                
                self.status_canvas.itemconfig(self.status_text_id,
                    text=f"[ EXPORTED ] Video saved to {os.path.basename(file_path)}")
                    
            except Exception as e:
                import traceback
                print(f"âœ— Video export failed:")
                traceback.print_exc()
                messagebox.showerror("Error", f"Failed to export video:\n\n{str(e)}\n\nCheck terminal for details.")

    
    def export_audio(self):
        """å¯¼å‡ºéŸ³é¢‘WAVæ–‡ä»¶"""
        if not self.melody_generator.recorded_notes:
            messagebox.showwarning("No Audio", "No audio to export!")
            return
        
        file_path = filedialog.asksaveasfilename(
            title="Export Audio",
            defaultextension=".wav",
            filetypes=[
                ("WAV Audio", "*.wav"),
                ("All Files", "*.*")
            ]
        )
        
        if file_path:
            try:
                import numpy as np
                import wave
                
                self.status_canvas.itemconfig(self.status_text_id,
                    text="[ EXPORTING ] Rendering audio...")
                self.root.update()
                
                # ç”ŸæˆéŸ³é¢‘æ³¢å½¢
                sample_rate = 44100
                audio_data = []
                
                for note_info in self.melody_generator.recorded_notes:
                    pitch = note_info['pitch']
                    duration = note_info['duration']
                    velocity = note_info['velocity']
                    
                    # ç”Ÿæˆæ–¹æ³¢éŸ³ç¬¦
                    frequency = 440.0 * (2 ** ((pitch - 69) / 12.0))
                    num_samples = int(duration * sample_rate)
                    t = np.linspace(0, duration, num_samples, False)
                    
                    # æ–¹æ³¢ç”Ÿæˆï¼ˆ8-bité£æ ¼ï¼‰
                    wave_data = np.sign(np.sin(2 * np.pi * frequency * t))
                    wave_data *= (velocity / 127.0) * 0.3  # éŸ³é‡è°ƒæ•´
                    
                    audio_data.extend(wave_data)
                
                # è½¬æ¢ä¸º16-bit PCM
                audio_data = np.array(audio_data)
                audio_data = np.int16(audio_data * 32767)
                
                # ä¿å­˜WAVæ–‡ä»¶
                with wave.open(file_path, 'w') as wav_file:
                    wav_file.setnchannels(1)  # å•å£°é“
                    wav_file.setsampwidth(2)  # 16-bit
                    wav_file.setframerate(sample_rate)
                    wav_file.writeframes(audio_data.tobytes())
                
                duration_sec = len(audio_data) / sample_rate
                messagebox.showinfo("Success", 
                    f"Audio exported successfully!\n\n"
                    f"Notes: {len(self.melody_generator.recorded_notes)}\n"
                    f"Duration: {duration_sec:.2f}s\n"
                    f"Sample Rate: {sample_rate} Hz\n"
                    f"File: {file_path}")
                
                self.status_canvas.itemconfig(self.status_text_id,
                    text=f"[ EXPORTED ] Audio saved to {os.path.basename(file_path)}")
                    
            except Exception as e:
                import traceback
                traceback.print_exc()
                messagebox.showerror("Error", f"Failed to export audio: {str(e)}")
    
    def reset_and_load(self):
        """Reset and load new image"""
        self.current_image_path = None
        self.current_image = None
        self.pixelated_image = None
        self.melody_generator.clear_recorded_notes()  # æ¸…ç©ºå½•åˆ¶çš„éŸ³ç¬¦
        self.draw_load_button()
        self.status_canvas.itemconfig(self.status_text_id,
            text="[ READY ] Load image to start")
        
        # è‡ªåŠ¨æ‰“å¼€æ–‡ä»¶é€‰æ‹©å¯¹è¯æ¡†
        self.root.after(100, self.load_image)


def main():
    root = tk.Tk()
    app = Image2MelodyApp(root)
    root.mainloop()


if __name__ == "__main__":
    main()
